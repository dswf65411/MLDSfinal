{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import collections\n",
    "import time\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# hw_dir = '/Users/Brian/Desktop/MLDS/FinalProject/CNN'\n",
    "# hw_dir = '/Users/yao/Desktop/trueman/big4/MLDS/final'\n",
    "hw_dir = '/home/yao/gm/mlds/final'\n",
    "test_max_slen = 20\n",
    "train_softmax_slen = 50\n",
    "train_max_slen = 70\n",
    "\n",
    "max_slen = 43\n",
    "min_slen = 7\n",
    "\n",
    "batch_size = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('%s/all_pickles'%hw_dir,'rb') as f1:\n",
    "    [train_data,test_data,word2ix,ix2word,vocab_size] = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "blank_ix = word2ix[' ']\n",
    "new_data = []\n",
    "for data in train_data:\n",
    "    temp = []\n",
    "    sc = 0\n",
    "    if(int(data[0]) < 3):\n",
    "        sc = 0\n",
    "    elif(int(data[0]) > 3):\n",
    "        sc = 1\n",
    "    else:\n",
    "        continue\n",
    "    temp.append(sc)\n",
    "    temp.append([int(x) for x in data[1].split(\" \")])\n",
    "    new_data.append(temp)\n",
    "train_data = new_data\n",
    "train_data = [i for i in train_data if len(i[1])<=70 and len(i[1])>=5]\n",
    "\n",
    "blank_ix = word2ix[' ']\n",
    "new_data = []\n",
    "for data in test_data:\n",
    "    temp = []\n",
    "    sc = 0\n",
    "    if(int(data[0]) < 3):\n",
    "        sc = 0\n",
    "    elif(int(data[0]) > 3):\n",
    "        sc = 1\n",
    "    else:\n",
    "        continue\n",
    "    temp.append(sc)\n",
    "    temp.append([int(x) for x in data[1].split(\" \")])\n",
    "#     temp[1].extend([13]*(max_slen-len(temp[1])))\n",
    "    new_data.append(temp)\n",
    "test_data = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amax = [len(i[1]) for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(amax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101930, 9264)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data_dict = dict()\n",
    "for i in train_data:\n",
    "    len_cmmt = len(i[1])\n",
    "    if len_cmmt in train_data_dict:\n",
    "        train_data_dict[len_cmmt].append(i)\n",
    "    else:\n",
    "        train_data_dict[len_cmmt] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dict = dict()\n",
    "for i in test_data:\n",
    "    len_cmmt = len(i[1])\n",
    "    if len_cmmt in train_data_dict:\n",
    "        train_data_dict[len_cmmt].append(i)\n",
    "    else:\n",
    "        train_data_dict[len_cmmt] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# len_pos    = max_slen  # 現在在長度多少的file，從長的開始\n",
    "# batch_pos  = 0\n",
    "# def get_batch(batch_size):\n",
    "#     global train_data_dict, len_pos, batch_pos\n",
    "#     batch_size = (batch_size//len_pos)+1 # 越長的句子一個batch就讀越少句，+1是避免0的狀況\n",
    "#     # ====================回傳用的參數=============================\n",
    "#     is_eoi = False  # end of iteration\n",
    "#     is_eof = False\n",
    "#     slen  = len_pos\n",
    "#     # ===========================================================\n",
    "#     # ====================從檔案中讀batch_size句===================\n",
    "#     now_datas = train_data_dict[len_pos][batch_pos:batch_pos+batch_size]\n",
    "#     batch_pos+=batch_size\n",
    "#     if len(now_datas)<batch_size:\n",
    "#         batch_pos=0\n",
    "#         is_eof = True\n",
    "#     # ===========================================================\n",
    "#     batch_size = len(now_datas) # 因為有可能在檔案的尾巴 讀不滿完整的batch_size 故在此更新batch_size\n",
    "#     # ==================若現在的檔案讀完============================\n",
    "#     if is_eof == True:\n",
    "#         random.shuffle(train_data_dict[len_pos])\n",
    "#         if len_pos == min_slen: # 一個iteration跑完 重新再跑\n",
    "#             len_pos = max_slen\n",
    "#             is_eoi = True\n",
    "#         else:                      # 現在這長度的file完了 開始讀len_pos-1的檔案\n",
    "#             len_pos -= 1\n",
    "#         if batch_size == 0: # 剛好讀到尾巴了\n",
    "#             return is_eoi,is_eof,None,None,slen,batch_size\n",
    "#     # ============================================================\n",
    "        \n",
    "#     score = np.array([i[0] for i in now_datas])\n",
    "#     cmmt = np.array([i[1] for i in now_datas])\n",
    "#     return is_eoi,is_eof,score,cmmt,slen,batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_slen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_pos    = max_slen  # 現在在長度多少的file，從長的開始\n",
    "pad_ix = word2ix['<PAD>']\n",
    "batch_pos  = 0\n",
    "def get_batch(batch_size):\n",
    "    global train_data_dict, len_pos, batch_pos\n",
    "    batch_size = (batch_size//len_pos)+1 # 越長的句子一個batch就讀越少句，+1是避免0的狀況\n",
    "    # ====================回傳用的參數=============================\n",
    "    is_eoi = False  # end of iteration\n",
    "    is_eof = False\n",
    "    slen  = len_pos\n",
    "    # ===========================================================\n",
    "    # ====================從檔案中讀batch_size句===================\n",
    "#     try:\n",
    "    now_datas = train_data_dict[len_pos][batch_pos:batch_pos+batch_size]\n",
    "#     except:\n",
    "#         return False,True,None,None,0,0\n",
    "    batch_pos+=batch_size\n",
    "    if len(now_datas)<batch_size:\n",
    "        batch_pos=0\n",
    "        is_eof = True\n",
    "    # ===========================================================\n",
    "    batch_size = len(now_datas) # 因為有可能在檔案的尾巴 讀不滿完整的batch_size 故在此更新batch_size\n",
    "    # ==================若現在的檔案讀完============================\n",
    "    if is_eof == True:\n",
    "        random.shuffle(train_data_dict[len_pos])\n",
    "        if len_pos == min_slen: # 一個iteration跑完 重新再跑\n",
    "            len_pos = max_slen\n",
    "            is_eoi = True\n",
    "        else:                      # 現在這長度的file完了 開始讀len_pos-1的檔案\n",
    "            while len_pos >= min_slen:\n",
    "                len_pos -= 1\n",
    "                if len_pos in train_data_dict:\n",
    "                    break\n",
    "            \n",
    "            \n",
    "        if batch_size == 0: # 剛好讀到尾巴了\n",
    "            return is_eoi,is_eof,None,None,slen,batch_size\n",
    "    # ============================================================\n",
    "        \n",
    "    score = np.array([i[0] for i in now_datas])\n",
    "    cmmt = np.array([i[1]+[pad_ix]*(70-slen) for i in now_datas])\n",
    "    return is_eoi,is_eof,score,cmmt,slen,batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001                   \n",
    "training_iters = 100      \n",
    "\n",
    "n_vocab_size = vocab_size\n",
    "sequence_length = 70   # 一句多少個字\n",
    "embedding_size = 300\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 100 \n",
    "num_classes = 2\n",
    "n_batch_size = 500\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    CNN 用來做情感分析\n",
    "    Model structure : input layer -> convolution layer -> max-pooling -> softmax\n",
    "\"\"\"\n",
    "\n",
    "# input 的 placeholder , x [batch_size, sequence_length] -> 因為句長不固定所以第二維sequence length 設為placeholder\n",
    "input_x = tf.placeholder(tf.int32, [None,None], name=\"input_x\")\n",
    "input_y = tf.placeholder(tf.int32, [None,], name=\"input_y\")\n",
    "ph_batch_size = tf.placeholder(tf.int32,[], name=\"ph_batch_size\")\n",
    "drop_rate = tf.placeholder(tf.float32,[], name=\"drop_rate\")\n",
    "\"\"\"\n",
    "    設定word embedding , 使用 embedding lookup (給我字的id,回傳word_embedding)\n",
    "    有人說tensorflow 目前不支援使用 gpu 操作embedding (?)\n",
    "    tf.name_scope 會創造一個top-level 的 node,並將所有相關的 operation 加到 node 上\n",
    "    在TensorBoard 可以看得比較清楚\n",
    "\"\"\"\n",
    "# with tf.name_scope(\"embedding\"):\n",
    "\n",
    "    # 預設word embedding 為 -1 ~ 1 之間的 亂數\n",
    "w_Embd = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, embedding_size], -1.0 , 1.0),\n",
    "        name = \"w_Embd\")\n",
    "\n",
    "# embedding lookup 回傳 [batch_size, sequence_length, word_embedding]\n",
    "embedded_words = tf.nn.embedding_lookup(w_Embd, input_x) \n",
    "y_embed = tf.constant(np.eye(num_classes))\n",
    "y_emb = tf.nn.embedding_lookup(y_embed,input_y)\n",
    "# tensorflow 的 conV2d 吃的是4維的向量,因此將其expand 成4維\n",
    "embedded_words_expand = tf.expand_dims(embedded_words, -1)\n",
    "embedded_words_expand = tf.transpose(embedded_words_expand,[0,1,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    這邊根據不同的filter size 先各自創造自己的convolution layer + max-pooling layer\n",
    "    最後再合併變成一個大的feature map\n",
    "\"\"\"\n",
    "max_pooled_output = []\n",
    "for i, filter_size in enumerate(filter_sizes):\n",
    "\n",
    "    # Convolution layer\n",
    "    #filter_shape = [filter_size, embedding_size , 1 , num_filters]\n",
    "    filter_shape = [filter_size, 1 , embedding_size , num_filters]\n",
    "\n",
    "    # initialize weight and bias\n",
    "    weight = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"weight\")\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"bias\")\n",
    "\n",
    "    #     if(i > 0):\n",
    "    #         tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    conv = tf.nn.conv2d(\n",
    "        embedded_words_expand,\n",
    "        weight,\n",
    "        strides=[1,1,1,1],\n",
    "        padding=\"SAME\",    #narrow conv\n",
    "        name=\"conv\"\n",
    "    ) \n",
    "\n",
    "    # 過relu\n",
    "    h = tf.nn.relu(tf.nn.bias_add(conv, bias), name=\"relu\") # =>(bsize,seq,1,fil)\n",
    "\n",
    "    # max-pooling\n",
    "    # ksize 這邊的 第二維 就是指filter 總共會滑過去幾次 -> sequence_length - filter_size + 1\n",
    "    # input : [1,0,3,4] , filter_size : 2 , output: [[1,0],[0,3],[3,4]] -> length : 4 - 2 + 1 = 3 \n",
    "    \n",
    "    pooled = tf.nn.max_pool(\n",
    "        h,\n",
    "        ksize=[1, sequence_length , 1, 1],     \n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='VALID',\n",
    "        name=\"pool\" \n",
    "    )\n",
    "\n",
    "    max_pooled_output.append(pooled) # => [(bsize,1,1,fil)]*fil_size\n",
    "\n",
    "# 合併 所有的 feature\n",
    "num_filters_total = num_filters * len(filter_sizes)\n",
    "h_pool = tf.concat(max_pooled_output, 3) # =>(bsize,1,1,fil*fil_size)\n",
    "h_pool_flat = tf.reshape(h_pool, [-1,num_filters_total]) # =>(bsize,fil*fil_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!\n",
    "# dropout layer\n",
    "# with tf.name_scope(\"dropout\"):\n",
    "\n",
    "h_drop = h_pool_flat\n",
    "#h_drop = tf.nn.dropout(h_pool_flat, dropout_rate) # =>(bsize,fil*fil_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Fully-connected Layer , calculate score , prediction\n",
    "# with tf.name_scope(\"output\"):\n",
    "W = tf.Variable(tf.truncated_normal([num_filters_total, num_classes], stddev=0.1), name=\"W\")\n",
    "b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "scores = tf.nn.xw_plus_b(h_drop, W, b, name=\"scores\") # =>(bsize,num_classes)\n",
    "predictions = tf.argmax(scores, 1, name=\"predictions\") # =>(bsize,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate mean cross-entropy loss\n",
    "# with tf.name_scope(\"loss\"):\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_emb, logits=scores))\n",
    "# (bsize,num_classes),(bsize,num_classes)=>float\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracy\n",
    "# with tf.name_scope(\"accuracy\"):\n",
    "correct_predictions = tf.equal(predictions, tf.argmax(y_emb, 1)) # (bsize,1),(bsize,1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initialize \n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0 batch:200 loss:0.198101 accuracy:0.945055 55\n",
      "iter:0 batch:400 loss:0.101613 accuracy:0.948454 52\n",
      "iter:0 batch:600 loss:0.168690 accuracy:0.925234 47\n",
      "iter:1 batch:200 loss:0.248023 accuracy:0.908046 58\n",
      "iter:1 batch:400 loss:0.169457 accuracy:0.912088 55\n",
      "iter:1 batch:600 loss:0.085744 accuracy:0.979381 52\n",
      "iter:1 batch:800 loss:0.133199 accuracy:0.963303 46\n",
      "iter:2 batch:200 loss:0.141411 accuracy:0.919540 58\n",
      "iter:2 batch:400 loss:0.049070 accuracy:0.989011 55\n",
      "iter:2 batch:600 loss:0.199310 accuracy:0.927835 52\n",
      "iter:2 batch:800 loss:0.095824 accuracy:0.972477 46\n",
      "iter:3 batch:200 loss:0.154549 accuracy:0.931035 58\n",
      "iter:3 batch:400 loss:0.093724 accuracy:0.956044 55\n",
      "iter:3 batch:600 loss:0.206170 accuracy:0.969072 52\n",
      "iter:3 batch:800 loss:0.078451 accuracy:0.972477 46\n",
      "iter:4 batch:200 loss:0.104470 accuracy:0.931035 58\n",
      "iter:4 batch:400 loss:0.103287 accuracy:0.967033 55\n",
      "iter:4 batch:600 loss:0.074814 accuracy:0.979381 52\n",
      "iter:4 batch:800 loss:0.150094 accuracy:0.935780 46\n",
      "iter:5 batch:200 loss:0.046323 accuracy:0.988506 58\n",
      "iter:5 batch:400 loss:0.116722 accuracy:0.967033 55\n",
      "iter:5 batch:600 loss:0.071282 accuracy:0.969072 52\n",
      "iter:5 batch:800 loss:0.089072 accuracy:0.963303 46\n",
      "iter:6 batch:200 loss:0.160979 accuracy:0.942529 58\n",
      "iter:6 batch:400 loss:0.081437 accuracy:0.967033 55\n",
      "iter:6 batch:600 loss:0.109852 accuracy:0.938144 52\n",
      "iter:6 batch:800 loss:0.125158 accuracy:0.963303 46\n",
      "iter:7 batch:200 loss:0.074583 accuracy:0.965517 58\n",
      "iter:7 batch:400 loss:0.103204 accuracy:0.956044 55\n",
      "iter:7 batch:600 loss:0.098205 accuracy:0.979381 52\n",
      "iter:7 batch:800 loss:0.114087 accuracy:0.935780 46\n",
      "iter:8 batch:200 loss:0.079269 accuracy:0.965517 58\n",
      "iter:8 batch:400 loss:0.042705 accuracy:0.978022 55\n",
      "iter:8 batch:600 loss:0.027286 accuracy:0.989691 52\n",
      "iter:8 batch:800 loss:0.052363 accuracy:0.963303 46\n",
      "iter:9 batch:200 loss:0.099493 accuracy:0.965517 58\n",
      "iter:9 batch:400 loss:0.077072 accuracy:0.967033 55\n",
      "iter:9 batch:600 loss:0.026579 accuracy:1.000000 52\n",
      "iter:9 batch:800 loss:0.034333 accuracy:1.000000 46\n",
      "iter:10 batch:200 loss:0.018536 accuracy:1.000000 58\n",
      "iter:10 batch:400 loss:0.080511 accuracy:0.978022 55\n",
      "iter:10 batch:600 loss:0.103062 accuracy:0.948454 52\n",
      "iter:10 batch:800 loss:0.171112 accuracy:0.954128 46\n",
      "iter:11 batch:200 loss:0.059340 accuracy:0.977012 58\n",
      "iter:11 batch:400 loss:0.043264 accuracy:0.978022 55\n",
      "iter:11 batch:600 loss:0.077004 accuracy:0.958763 52\n",
      "iter:11 batch:800 loss:0.082911 accuracy:0.963303 46\n",
      "iter:12 batch:200 loss:0.045042 accuracy:0.977012 58\n",
      "iter:12 batch:400 loss:0.105709 accuracy:0.956044 55\n",
      "iter:12 batch:600 loss:0.108164 accuracy:0.969072 52\n",
      "iter:12 batch:800 loss:0.050014 accuracy:0.981651 46\n",
      "iter:13 batch:200 loss:0.016463 accuracy:1.000000 58\n",
      "iter:13 batch:400 loss:0.054949 accuracy:0.978022 55\n",
      "iter:13 batch:600 loss:0.078012 accuracy:0.969072 52\n",
      "iter:13 batch:800 loss:0.084979 accuracy:0.972477 46\n",
      "iter:14 batch:200 loss:0.041961 accuracy:0.988506 58\n",
      "iter:14 batch:400 loss:0.031378 accuracy:0.989011 55\n",
      "iter:14 batch:600 loss:0.071857 accuracy:0.979381 52\n",
      "iter:14 batch:800 loss:0.035645 accuracy:0.990826 46\n",
      "iter:15 batch:200 loss:0.037159 accuracy:0.988506 58\n",
      "iter:15 batch:400 loss:0.030082 accuracy:0.989011 55\n",
      "iter:15 batch:600 loss:0.016662 accuracy:0.989691 52\n",
      "iter:15 batch:800 loss:0.105090 accuracy:0.963303 46\n",
      "iter:16 batch:200 loss:0.030048 accuracy:0.988506 58\n",
      "iter:16 batch:400 loss:0.061937 accuracy:0.978022 55\n",
      "iter:16 batch:600 loss:0.039344 accuracy:0.989691 52\n",
      "iter:16 batch:800 loss:0.062584 accuracy:0.972477 46\n",
      "iter:17 batch:200 loss:0.034027 accuracy:0.988506 58\n",
      "iter:17 batch:400 loss:0.051070 accuracy:0.978022 55\n",
      "iter:17 batch:600 loss:0.038069 accuracy:0.989691 52\n",
      "iter:17 batch:800 loss:0.018048 accuracy:0.990826 46\n",
      "iter:18 batch:200 loss:0.031751 accuracy:0.977011 58\n",
      "iter:18 batch:400 loss:0.059824 accuracy:0.989011 55\n",
      "iter:18 batch:600 loss:0.022624 accuracy:0.989691 52\n",
      "iter:18 batch:800 loss:0.076407 accuracy:0.954128 46\n",
      "iter:19 batch:200 loss:0.072976 accuracy:0.988506 58\n",
      "iter:19 batch:400 loss:0.036853 accuracy:0.989011 55\n",
      "iter:19 batch:600 loss:0.036109 accuracy:0.969072 52\n",
      "iter:19 batch:800 loss:0.061615 accuracy:0.981651 46\n",
      "iter:20 batch:200 loss:0.006748 accuracy:1.000000 58\n",
      "iter:20 batch:400 loss:0.042858 accuracy:0.978022 55\n",
      "iter:20 batch:600 loss:0.041112 accuracy:0.989691 52\n",
      "iter:20 batch:800 loss:0.080845 accuracy:0.963303 46\n",
      "iter:21 batch:200 loss:0.102992 accuracy:0.965517 58\n",
      "iter:21 batch:400 loss:0.031952 accuracy:0.989011 55\n",
      "iter:21 batch:600 loss:0.030390 accuracy:0.989691 52\n",
      "iter:21 batch:800 loss:0.015503 accuracy:1.000000 46\n",
      "iter:22 batch:200 loss:0.079179 accuracy:0.988506 58\n",
      "iter:22 batch:400 loss:0.007251 accuracy:1.000000 55\n",
      "iter:22 batch:600 loss:0.015765 accuracy:1.000000 52\n",
      "iter:22 batch:800 loss:0.089747 accuracy:0.972477 46\n",
      "iter:23 batch:200 loss:0.115126 accuracy:0.965517 58\n",
      "iter:23 batch:400 loss:0.051777 accuracy:0.967033 55\n",
      "iter:23 batch:600 loss:0.029786 accuracy:0.989691 52\n",
      "iter:23 batch:800 loss:0.033263 accuracy:0.990826 46\n",
      "iter:24 batch:200 loss:0.024180 accuracy:0.977012 58\n",
      "iter:24 batch:400 loss:0.131062 accuracy:0.945055 55\n",
      "iter:24 batch:600 loss:0.067379 accuracy:0.958763 52\n",
      "iter:24 batch:800 loss:0.036494 accuracy:0.981651 46\n",
      "iter:25 batch:200 loss:0.024601 accuracy:0.988506 58\n",
      "iter:25 batch:400 loss:0.078679 accuracy:0.978022 55\n",
      "iter:25 batch:600 loss:0.026463 accuracy:0.979381 52\n",
      "iter:25 batch:800 loss:0.142036 accuracy:0.944954 46\n",
      "iter:26 batch:200 loss:0.124767 accuracy:0.977011 58\n",
      "iter:26 batch:400 loss:0.098825 accuracy:0.967033 55\n",
      "iter:26 batch:600 loss:0.067375 accuracy:0.969072 52\n",
      "iter:26 batch:800 loss:0.068809 accuracy:0.981651 46\n",
      "iter:27 batch:200 loss:0.004193 accuracy:1.000000 58\n",
      "iter:27 batch:400 loss:0.045537 accuracy:0.989011 55\n",
      "iter:27 batch:600 loss:0.012845 accuracy:1.000000 52\n",
      "iter:27 batch:800 loss:0.025914 accuracy:0.990826 46\n",
      "iter:28 batch:200 loss:0.049746 accuracy:0.988506 58\n",
      "iter:28 batch:400 loss:0.057983 accuracy:0.978022 55\n",
      "iter:28 batch:600 loss:0.027001 accuracy:0.979381 52\n",
      "iter:28 batch:800 loss:0.035130 accuracy:0.981651 46\n",
      "iter:29 batch:200 loss:0.003277 accuracy:1.000000 58\n",
      "iter:29 batch:400 loss:0.011297 accuracy:1.000000 55\n",
      "iter:29 batch:600 loss:0.046588 accuracy:0.969072 52\n",
      "iter:29 batch:800 loss:0.007876 accuracy:1.000000 46\n",
      "iter:30 batch:200 loss:0.043135 accuracy:0.988506 58\n",
      "iter:30 batch:400 loss:0.014905 accuracy:1.000000 55\n",
      "iter:30 batch:600 loss:0.008866 accuracy:1.000000 52\n",
      "iter:30 batch:800 loss:0.024813 accuracy:0.990826 46\n",
      "iter:31 batch:200 loss:0.008025 accuracy:1.000000 58\n",
      "iter:31 batch:400 loss:0.009736 accuracy:1.000000 55\n",
      "iter:31 batch:600 loss:0.029626 accuracy:1.000000 52\n",
      "iter:31 batch:800 loss:0.013491 accuracy:1.000000 46\n",
      "iter:32 batch:200 loss:0.027229 accuracy:0.988506 58\n",
      "iter:32 batch:400 loss:0.049627 accuracy:0.967033 55\n",
      "iter:32 batch:600 loss:0.039136 accuracy:0.979381 52\n",
      "iter:32 batch:800 loss:0.044775 accuracy:0.981651 46\n",
      "iter:33 batch:200 loss:0.153350 accuracy:0.954023 58\n",
      "iter:33 batch:400 loss:0.034138 accuracy:0.978022 55\n",
      "iter:33 batch:600 loss:0.030121 accuracy:0.989691 52\n",
      "iter:33 batch:800 loss:0.020758 accuracy:0.990826 46\n",
      "iter:34 batch:200 loss:0.095664 accuracy:0.988506 58\n",
      "iter:34 batch:400 loss:0.017468 accuracy:1.000000 55\n",
      "iter:34 batch:600 loss:0.037001 accuracy:0.979381 52\n",
      "iter:34 batch:800 loss:0.019201 accuracy:0.990826 46\n",
      "iter:35 batch:200 loss:0.022079 accuracy:0.988506 58\n",
      "iter:35 batch:400 loss:0.047095 accuracy:0.967033 55\n",
      "iter:35 batch:600 loss:0.102134 accuracy:0.948454 52\n",
      "iter:35 batch:800 loss:0.012643 accuracy:1.000000 46\n",
      "iter:36 batch:200 loss:0.031002 accuracy:0.977011 58\n",
      "iter:36 batch:400 loss:0.029218 accuracy:1.000000 55\n",
      "iter:36 batch:600 loss:0.059300 accuracy:0.989691 52\n",
      "iter:36 batch:800 loss:0.029478 accuracy:0.981651 46\n",
      "iter:37 batch:200 loss:0.012227 accuracy:0.988506 58\n",
      "iter:37 batch:400 loss:0.020119 accuracy:0.989011 55\n",
      "iter:37 batch:600 loss:0.010154 accuracy:1.000000 52\n",
      "iter:37 batch:800 loss:0.005900 accuracy:1.000000 46\n",
      "iter:38 batch:200 loss:0.025019 accuracy:0.988506 58\n",
      "iter:38 batch:400 loss:0.014139 accuracy:0.989011 55\n",
      "iter:38 batch:600 loss:0.022022 accuracy:0.979381 52\n",
      "iter:38 batch:800 loss:0.004828 accuracy:1.000000 46\n",
      "iter:39 batch:200 loss:0.127145 accuracy:0.954023 58\n",
      "iter:39 batch:400 loss:0.019494 accuracy:0.989011 55\n",
      "iter:39 batch:600 loss:0.049763 accuracy:0.979381 52\n",
      "iter:39 batch:800 loss:0.051834 accuracy:0.981651 46\n",
      "iter:40 batch:200 loss:0.010406 accuracy:1.000000 58\n",
      "iter:40 batch:400 loss:0.055246 accuracy:0.989011 55\n",
      "iter:40 batch:600 loss:0.057514 accuracy:0.979381 52\n",
      "iter:40 batch:800 loss:0.011459 accuracy:1.000000 46\n",
      "iter:41 batch:200 loss:0.017818 accuracy:0.988506 58\n",
      "iter:41 batch:400 loss:0.050532 accuracy:0.978022 55\n",
      "iter:41 batch:600 loss:0.068654 accuracy:0.969072 52\n",
      "iter:41 batch:800 loss:0.016347 accuracy:1.000000 46\n",
      "iter:42 batch:200 loss:0.013508 accuracy:1.000000 58\n",
      "iter:42 batch:400 loss:0.022864 accuracy:0.989011 55\n",
      "iter:42 batch:600 loss:0.007637 accuracy:1.000000 52\n",
      "iter:42 batch:800 loss:0.050501 accuracy:0.981651 46\n",
      "iter:43 batch:200 loss:0.038458 accuracy:0.988506 58\n",
      "iter:43 batch:400 loss:0.032478 accuracy:0.989011 55\n",
      "iter:43 batch:600 loss:0.026645 accuracy:0.979381 52\n",
      "iter:43 batch:800 loss:0.007939 accuracy:1.000000 46\n",
      "iter:44 batch:200 loss:0.053500 accuracy:0.988506 58\n",
      "iter:44 batch:400 loss:0.016033 accuracy:0.989011 55\n",
      "iter:44 batch:600 loss:0.014313 accuracy:1.000000 52\n",
      "iter:44 batch:800 loss:0.025301 accuracy:0.990826 46\n",
      "iter:45 batch:200 loss:0.028637 accuracy:0.988506 58\n",
      "iter:45 batch:400 loss:0.056823 accuracy:0.978022 55\n",
      "iter:45 batch:600 loss:0.043292 accuracy:0.989691 52\n",
      "iter:45 batch:800 loss:0.003568 accuracy:1.000000 46\n",
      "iter:46 batch:200 loss:0.005540 accuracy:1.000000 58\n",
      "iter:46 batch:400 loss:0.015757 accuracy:0.989011 55\n",
      "iter:46 batch:600 loss:0.022197 accuracy:0.989691 52\n",
      "iter:46 batch:800 loss:0.069167 accuracy:0.981651 46\n",
      "iter:47 batch:200 loss:0.025539 accuracy:0.988506 58\n",
      "iter:47 batch:400 loss:0.011297 accuracy:1.000000 55\n",
      "iter:47 batch:600 loss:0.086349 accuracy:0.958763 52\n",
      "iter:47 batch:800 loss:0.025395 accuracy:0.990826 46\n",
      "iter:48 batch:200 loss:0.010021 accuracy:1.000000 58\n",
      "iter:48 batch:400 loss:0.014468 accuracy:1.000000 55\n",
      "iter:48 batch:600 loss:0.127422 accuracy:0.958763 52\n",
      "iter:48 batch:800 loss:0.025350 accuracy:0.990826 46\n",
      "iter:49 batch:200 loss:0.080886 accuracy:0.977012 58\n",
      "iter:49 batch:400 loss:0.018286 accuracy:0.989011 55\n",
      "iter:49 batch:600 loss:0.051157 accuracy:0.979381 52\n",
      "iter:49 batch:800 loss:0.009478 accuracy:1.000000 46\n",
      "iter:50 batch:200 loss:0.011208 accuracy:1.000000 58\n",
      "iter:50 batch:400 loss:0.036273 accuracy:0.967033 55\n",
      "iter:50 batch:600 loss:0.018229 accuracy:0.989691 52\n",
      "iter:50 batch:800 loss:0.022234 accuracy:0.990826 46\n",
      "iter:51 batch:200 loss:0.127241 accuracy:0.988506 58\n",
      "iter:51 batch:400 loss:0.055146 accuracy:0.978022 55\n",
      "iter:51 batch:600 loss:0.039129 accuracy:0.979381 52\n",
      "iter:51 batch:800 loss:0.004311 accuracy:1.000000 46\n",
      "iter:52 batch:200 loss:0.046403 accuracy:0.965517 58\n",
      "iter:52 batch:400 loss:0.061111 accuracy:0.978022 55\n",
      "iter:52 batch:600 loss:0.007151 accuracy:1.000000 52\n",
      "iter:52 batch:800 loss:0.042924 accuracy:0.963303 46\n",
      "iter:53 batch:200 loss:0.018571 accuracy:0.988506 58\n",
      "iter:53 batch:400 loss:0.063295 accuracy:0.967033 55\n",
      "iter:53 batch:600 loss:0.025077 accuracy:0.989691 52\n",
      "iter:53 batch:800 loss:0.061335 accuracy:0.981651 46\n",
      "iter:54 batch:200 loss:0.023786 accuracy:0.988506 58\n",
      "iter:54 batch:400 loss:0.028563 accuracy:0.978022 55\n",
      "iter:54 batch:600 loss:0.010193 accuracy:0.989691 52\n",
      "iter:54 batch:800 loss:0.042657 accuracy:0.981651 46\n",
      "iter:55 batch:200 loss:0.006521 accuracy:1.000000 58\n",
      "iter:55 batch:400 loss:0.093982 accuracy:0.978022 55\n",
      "iter:55 batch:600 loss:0.021899 accuracy:0.989691 52\n",
      "iter:55 batch:800 loss:0.024177 accuracy:0.990826 46\n",
      "iter:56 batch:200 loss:0.009364 accuracy:1.000000 58\n",
      "iter:56 batch:400 loss:0.021461 accuracy:0.989011 55\n",
      "iter:56 batch:600 loss:0.040575 accuracy:0.989691 52\n",
      "iter:56 batch:800 loss:0.021433 accuracy:0.990826 46\n",
      "iter:57 batch:200 loss:0.096898 accuracy:0.988506 58\n",
      "iter:57 batch:400 loss:0.054317 accuracy:0.989011 55\n",
      "iter:57 batch:600 loss:0.039829 accuracy:0.979381 52\n",
      "iter:57 batch:800 loss:0.043820 accuracy:0.990826 46\n",
      "iter:58 batch:200 loss:0.003153 accuracy:1.000000 58\n",
      "iter:58 batch:400 loss:0.006679 accuracy:1.000000 55\n",
      "iter:58 batch:600 loss:0.048376 accuracy:0.979381 52\n",
      "iter:58 batch:800 loss:0.013027 accuracy:0.990826 46\n",
      "iter:59 batch:200 loss:0.013081 accuracy:1.000000 58\n",
      "iter:59 batch:400 loss:0.003553 accuracy:1.000000 55\n",
      "iter:59 batch:600 loss:0.033432 accuracy:0.989691 52\n",
      "iter:59 batch:800 loss:0.034718 accuracy:0.981651 46\n",
      "iter:60 batch:200 loss:0.057090 accuracy:0.977012 58\n",
      "iter:60 batch:400 loss:0.016666 accuracy:0.989011 55\n",
      "iter:60 batch:600 loss:0.003161 accuracy:1.000000 52\n",
      "iter:60 batch:800 loss:0.020397 accuracy:0.990826 46\n",
      "iter:61 batch:200 loss:0.004881 accuracy:1.000000 58\n",
      "iter:61 batch:400 loss:0.022209 accuracy:0.989011 55\n",
      "iter:61 batch:600 loss:0.062884 accuracy:0.989691 52\n",
      "iter:61 batch:800 loss:0.076711 accuracy:0.963303 46\n",
      "iter:62 batch:200 loss:0.004477 accuracy:1.000000 58\n",
      "iter:62 batch:400 loss:0.014557 accuracy:0.989011 55\n",
      "iter:62 batch:600 loss:0.014229 accuracy:1.000000 52\n",
      "iter:62 batch:800 loss:0.029156 accuracy:0.981651 46\n",
      "iter:63 batch:200 loss:0.002094 accuracy:1.000000 58\n",
      "iter:63 batch:400 loss:0.002987 accuracy:1.000000 55\n",
      "iter:63 batch:600 loss:0.035027 accuracy:0.989691 52\n",
      "iter:63 batch:800 loss:0.005636 accuracy:1.000000 46\n",
      "iter:64 batch:200 loss:0.001879 accuracy:1.000000 58\n",
      "iter:64 batch:400 loss:0.006960 accuracy:1.000000 55\n",
      "iter:64 batch:600 loss:0.041115 accuracy:0.989691 52\n",
      "iter:64 batch:800 loss:0.026740 accuracy:0.990826 46\n",
      "iter:65 batch:200 loss:0.076162 accuracy:0.988506 58\n",
      "iter:65 batch:400 loss:0.006999 accuracy:1.000000 55\n",
      "iter:65 batch:600 loss:0.006490 accuracy:1.000000 52\n",
      "iter:65 batch:800 loss:0.048316 accuracy:0.990826 46\n",
      "iter:66 batch:200 loss:0.001836 accuracy:1.000000 58\n",
      "iter:66 batch:400 loss:0.118288 accuracy:0.967033 55\n",
      "iter:66 batch:600 loss:0.003724 accuracy:1.000000 52\n",
      "iter:66 batch:800 loss:0.079148 accuracy:0.990826 46\n",
      "iter:67 batch:200 loss:0.021179 accuracy:0.988506 58\n",
      "iter:67 batch:400 loss:0.052707 accuracy:0.978022 55\n",
      "iter:67 batch:600 loss:0.010002 accuracy:1.000000 52\n",
      "iter:67 batch:800 loss:0.034337 accuracy:0.981651 46\n",
      "iter:68 batch:200 loss:0.004527 accuracy:1.000000 58\n",
      "iter:68 batch:400 loss:0.014646 accuracy:1.000000 55\n",
      "iter:68 batch:600 loss:0.030747 accuracy:0.989691 52\n",
      "iter:68 batch:800 loss:0.017934 accuracy:0.990826 46\n",
      "iter:69 batch:200 loss:0.018659 accuracy:1.000000 58\n",
      "iter:69 batch:400 loss:0.024898 accuracy:0.978022 55\n",
      "iter:69 batch:600 loss:0.016780 accuracy:0.989691 52\n",
      "iter:69 batch:800 loss:0.016571 accuracy:0.990826 46\n",
      "iter:70 batch:200 loss:0.081198 accuracy:0.988506 58\n",
      "iter:70 batch:400 loss:0.029186 accuracy:0.989011 55\n",
      "iter:70 batch:600 loss:0.011486 accuracy:0.989691 52\n",
      "iter:70 batch:800 loss:0.082876 accuracy:0.972477 46\n",
      "iter:71 batch:200 loss:0.002577 accuracy:1.000000 58\n",
      "iter:71 batch:400 loss:0.006140 accuracy:1.000000 55\n",
      "iter:71 batch:600 loss:0.033477 accuracy:0.989691 52\n",
      "iter:71 batch:800 loss:0.037779 accuracy:0.990826 46\n",
      "iter:72 batch:200 loss:0.014696 accuracy:0.988506 58\n",
      "iter:72 batch:400 loss:0.077742 accuracy:0.956044 55\n",
      "iter:72 batch:600 loss:0.039474 accuracy:0.979381 52\n",
      "iter:72 batch:800 loss:0.016388 accuracy:0.990826 46\n",
      "iter:73 batch:200 loss:0.002676 accuracy:1.000000 58\n",
      "iter:73 batch:400 loss:0.057130 accuracy:0.978022 55\n",
      "iter:73 batch:600 loss:0.013456 accuracy:1.000000 52\n",
      "iter:73 batch:800 loss:0.009111 accuracy:0.990826 46\n",
      "iter:74 batch:200 loss:0.023003 accuracy:0.988506 58\n",
      "iter:74 batch:400 loss:0.019211 accuracy:0.989011 55\n",
      "iter:74 batch:600 loss:0.024108 accuracy:0.989691 52\n",
      "iter:74 batch:800 loss:0.028478 accuracy:0.981651 46\n",
      "iter:75 batch:200 loss:0.001409 accuracy:1.000000 58\n",
      "iter:75 batch:400 loss:0.002354 accuracy:1.000000 55\n",
      "iter:75 batch:600 loss:0.104515 accuracy:0.979381 52\n",
      "iter:75 batch:800 loss:0.013219 accuracy:0.990826 46\n",
      "iter:76 batch:200 loss:0.032578 accuracy:0.988506 58\n",
      "iter:76 batch:400 loss:0.046705 accuracy:0.978022 55\n",
      "iter:76 batch:600 loss:0.033211 accuracy:0.979381 52\n",
      "iter:76 batch:800 loss:0.042042 accuracy:0.990826 46\n",
      "iter:77 batch:200 loss:0.005152 accuracy:1.000000 58\n",
      "iter:77 batch:400 loss:0.006122 accuracy:1.000000 55\n",
      "iter:77 batch:600 loss:0.007293 accuracy:1.000000 52\n",
      "iter:77 batch:800 loss:0.038057 accuracy:0.981651 46\n",
      "iter:78 batch:200 loss:0.045025 accuracy:0.988506 58\n",
      "iter:78 batch:400 loss:0.043490 accuracy:0.978022 55\n",
      "iter:78 batch:600 loss:0.017665 accuracy:0.989691 52\n",
      "iter:78 batch:800 loss:0.043438 accuracy:0.981651 46\n",
      "iter:79 batch:200 loss:0.014424 accuracy:0.988506 58\n",
      "iter:79 batch:400 loss:0.000824 accuracy:1.000000 55\n",
      "iter:79 batch:600 loss:0.008187 accuracy:1.000000 52\n",
      "iter:79 batch:800 loss:0.024230 accuracy:0.990826 46\n",
      "iter:80 batch:200 loss:0.000609 accuracy:1.000000 58\n",
      "iter:80 batch:400 loss:0.038257 accuracy:0.989011 55\n",
      "iter:80 batch:600 loss:0.005948 accuracy:1.000000 52\n",
      "iter:80 batch:800 loss:0.003960 accuracy:1.000000 46\n",
      "iter:81 batch:200 loss:0.009712 accuracy:1.000000 58\n",
      "iter:81 batch:400 loss:0.015469 accuracy:0.989011 55\n",
      "iter:81 batch:600 loss:0.013384 accuracy:0.989691 52\n",
      "iter:81 batch:800 loss:0.024092 accuracy:0.990826 46\n",
      "iter:82 batch:200 loss:0.013046 accuracy:1.000000 58\n",
      "iter:82 batch:400 loss:0.061022 accuracy:0.989011 55\n",
      "iter:82 batch:600 loss:0.038175 accuracy:0.989691 52\n",
      "iter:82 batch:800 loss:0.011516 accuracy:1.000000 46\n",
      "iter:83 batch:200 loss:0.017609 accuracy:0.988506 58\n",
      "iter:83 batch:400 loss:0.011142 accuracy:1.000000 55\n",
      "iter:83 batch:600 loss:0.003206 accuracy:1.000000 52\n",
      "iter:83 batch:800 loss:0.032402 accuracy:0.981651 46\n",
      "iter:84 batch:200 loss:0.052754 accuracy:0.977012 58\n",
      "iter:84 batch:400 loss:0.001942 accuracy:1.000000 55\n",
      "iter:84 batch:600 loss:0.004759 accuracy:1.000000 52\n",
      "iter:84 batch:800 loss:0.004785 accuracy:1.000000 46\n",
      "iter:85 batch:200 loss:0.052848 accuracy:0.965517 58\n",
      "iter:85 batch:400 loss:0.000593 accuracy:1.000000 55\n",
      "iter:85 batch:600 loss:0.008122 accuracy:1.000000 52\n",
      "iter:85 batch:800 loss:0.002392 accuracy:1.000000 46\n",
      "iter:86 batch:200 loss:0.029144 accuracy:0.988506 58\n",
      "iter:86 batch:400 loss:0.068482 accuracy:0.978022 55\n",
      "iter:86 batch:600 loss:0.053282 accuracy:0.989691 52\n",
      "iter:86 batch:800 loss:0.097142 accuracy:0.972477 46\n",
      "iter:87 batch:200 loss:0.085260 accuracy:0.988506 58\n",
      "iter:87 batch:400 loss:0.023212 accuracy:0.989011 55\n",
      "iter:87 batch:600 loss:0.059078 accuracy:0.969072 52\n",
      "iter:87 batch:800 loss:0.012355 accuracy:0.990826 46\n",
      "iter:88 batch:200 loss:0.007276 accuracy:1.000000 58\n",
      "iter:88 batch:400 loss:0.046454 accuracy:0.978022 55\n",
      "iter:88 batch:600 loss:0.001514 accuracy:1.000000 52\n",
      "iter:88 batch:800 loss:0.036638 accuracy:0.972477 46\n",
      "iter:89 batch:200 loss:0.036842 accuracy:0.988506 58\n",
      "iter:89 batch:400 loss:0.014842 accuracy:0.989011 55\n",
      "iter:89 batch:600 loss:0.017563 accuracy:0.989691 52\n",
      "iter:89 batch:800 loss:0.005551 accuracy:1.000000 46\n",
      "iter:90 batch:200 loss:0.013665 accuracy:1.000000 58\n",
      "iter:90 batch:400 loss:0.002699 accuracy:1.000000 55\n",
      "iter:90 batch:600 loss:0.030299 accuracy:0.989691 52\n",
      "iter:90 batch:800 loss:0.008274 accuracy:1.000000 46\n",
      "iter:91 batch:200 loss:0.005178 accuracy:1.000000 58\n",
      "iter:91 batch:400 loss:0.057184 accuracy:0.978022 55\n",
      "iter:91 batch:600 loss:0.109241 accuracy:0.979381 52\n",
      "iter:91 batch:800 loss:0.002307 accuracy:1.000000 46\n",
      "iter:92 batch:200 loss:0.031936 accuracy:0.988506 58\n",
      "iter:92 batch:400 loss:0.034093 accuracy:0.967033 55\n",
      "iter:92 batch:600 loss:0.039442 accuracy:0.979381 52\n",
      "iter:92 batch:800 loss:0.026448 accuracy:0.990826 46\n",
      "iter:93 batch:200 loss:0.000670 accuracy:1.000000 58\n",
      "iter:93 batch:400 loss:0.010985 accuracy:1.000000 55\n",
      "iter:93 batch:600 loss:0.052865 accuracy:0.979381 52\n",
      "iter:93 batch:800 loss:0.032993 accuracy:0.981651 46\n",
      "iter:94 batch:200 loss:0.039432 accuracy:0.988506 58\n",
      "iter:94 batch:400 loss:0.017932 accuracy:0.989011 55\n",
      "iter:94 batch:600 loss:0.015994 accuracy:0.989691 52\n",
      "iter:94 batch:800 loss:0.017254 accuracy:0.990826 46\n",
      "iter:95 batch:200 loss:0.006412 accuracy:1.000000 58\n",
      "iter:95 batch:400 loss:0.027050 accuracy:0.989011 55\n",
      "iter:95 batch:600 loss:0.020523 accuracy:0.989691 52\n",
      "iter:95 batch:800 loss:0.009247 accuracy:1.000000 46\n",
      "iter:96 batch:200 loss:0.039751 accuracy:0.965517 58\n",
      "iter:96 batch:400 loss:0.005584 accuracy:1.000000 55\n",
      "iter:96 batch:600 loss:0.046474 accuracy:0.989691 52\n",
      "iter:96 batch:800 loss:0.044018 accuracy:0.963303 46\n",
      "iter:97 batch:200 loss:0.006361 accuracy:1.000000 58\n",
      "iter:97 batch:400 loss:0.012801 accuracy:0.989011 55\n",
      "iter:97 batch:600 loss:0.001329 accuracy:1.000000 52\n",
      "iter:97 batch:800 loss:0.030836 accuracy:0.990826 46\n",
      "iter:98 batch:200 loss:0.032695 accuracy:0.977012 58\n",
      "iter:98 batch:400 loss:0.017176 accuracy:0.989011 55\n",
      "iter:98 batch:600 loss:0.068572 accuracy:0.979381 52\n",
      "iter:98 batch:800 loss:0.052710 accuracy:0.981651 46\n",
      "iter:99 batch:200 loss:0.004273 accuracy:1.000000 58\n",
      "iter:99 batch:400 loss:0.134343 accuracy:0.989011 55\n",
      "iter:99 batch:600 loss:0.002944 accuracy:1.000000 52\n",
      "iter:99 batch:800 loss:0.001717 accuracy:1.000000 46\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "saver = tf.train.Saver()\n",
    "for i in range(training_iters):\n",
    "    is_eoi,is_eof,score,cmmt,slen,batch_size = get_batch(n_batch_size)\n",
    "    batch_now = 0\n",
    "    while(not is_eoi):\n",
    "        batch_now += 1\n",
    "        if batch_size == 0:\n",
    "            is_eoi,is_eof,score,cmmt,slen,batch_size = get_batch(n_batch_size)\n",
    "            continue\n",
    "        inp = {input_x:cmmt,input_y:score,ph_batch_size:batch_size,drop_rate:dropout_rate}\n",
    "        _,c,a = sess.run([train_op,loss,accuracy],inp)\n",
    "#         b = sess.run(pooled,inp)\n",
    "#         c = sess.run(h_pool,inp)\n",
    "#         input()\n",
    "        if batch_now%200==0:\n",
    "            print(\"iter:%d batch:%d loss:%f accuracy:%f %d\"%(i,batch_now,c,a,slen))\n",
    "            #     if (batch_now % 100 == 0):\n",
    "        is_eoi,is_eof,score,cmmt,slen,batch_size = get_batch(n_batch_size)\n",
    "    save_path = saver.save(sess,\"./CNN1_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 70, 300, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,'%s/CNN1_model.bin'%hw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ans_list = []\n",
    "is_eoi,is_eof,score,cmmt,slen,batch_size = get_batch(n_batch_size)\n",
    "batch_now = 0\n",
    "while(not is_eoi):\n",
    "    batch_now += 1\n",
    "    if batch_size == 0:\n",
    "        is_eoi,is_eof,score,cmmt,slen,batch_size = get_batch(n_batch_size)\n",
    "        continue\n",
    "    inp = {input_x:cmmt,input_y:score,ph_batch_size:batch_size,drop_rate:dropout_rate}\n",
    "    ans = sess.run(predictions,inp)\n",
    "#     print(\"fuck\")\n",
    "    ans_list.append([cmmt,score,ans])\n",
    "    is_eoi,is_eof,score,cmmt,slen,batch_size = get_batch(n_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans_list2 = []\n",
    "for ans in ans_list:\n",
    "    bsize = ans[0].shape[0]\n",
    "    ans[0] = ans[0].tolist()\n",
    "    ans[1] = ans[1].tolist()\n",
    "    ans[2] = ans[2].tolist()\n",
    "    for i in range(bsize):\n",
    "        cmmt = ''.join([ix2word[j] for j in ans[0][i]])\n",
    "        ans_list2.append([cmmt,ans[1][i],ans[2][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yes = 0\n",
    "yes_no = 0\n",
    "for i in ans_list2:\n",
    "    if i[1]==i[2]:\n",
    "        yes+=1\n",
    "    yes_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9394168466522678"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes/float(yes_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "different_CNN = [ans for ans in ans_list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('%s/output_diff_CNN.bin'%hw_dir,'wb') as f1:\n",
    "    pickle.dump(different_CNN,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
